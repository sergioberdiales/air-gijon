Resumen del Proyecto Air-Gijón
1. Descripción General
El proyecto Air-Gijón es una aplicación web diseñada para proporcionar predicciones diarias sobre la contaminación del aire en Gijón, además de permitir la consulta de datos históricos y actuales.

El cliente principal sería el Ayuntamiento de Gijón, que busca evaluar la viabilidad de una inversión en una plataforma más amplia y robusta.

2. Alcance del Sistema
Se utilizarán exclusivamente los datos públicos del Ayuntamiento de Gijón a través de su API de transparencia.

El sistema se centrará en la estación de monitorización de calidad del aire de la Avenida de la Constitución.

Se analizarán los contaminantes PM10 y NO2, con datos agregados a nivel diario.

La actualización de los datos será diaria.

Se implementará un diseño Mobile First para optimizar la experiencia en dispositivos móviles.

Los modelos de predicción se desarrollarán en Python o R.

El backend se desarrollará en Node.js y la base de datos será PostgreSQL.

El frontend se desarrollará con JavaScript y tecnologías impartidas en el ciclo formativo.

El despliegue se realizará en Render.

3. Tipologías de Usuarios
Usuarios externos: Ciudadanos que consultan la información sobre contaminación.

Usuarios anónimos: Pueden acceder a todas las funcionalidades de visualización.

Usuarios registrados: Pueden suscribirse a notificaciones y alertas sobre contaminación.

Usuarios internos / gestores: Pueden modificar los avisos y consejos en función de los niveles de contaminación.

Usuarios internos avanzados: Analizan las predicciones y comparan los datos reales con los estimados, generando informes de seguimiento.

4. Restricciones
Dependencia de la API del Ayuntamiento para la obtención de datos actualizados.

Proyecto desarrollado y mantenido por una sola persona.

Riesgos asociados a la precisión de las predicciones, lo que puede generar críticas públicas.

Recursos limitados en términos de infraestructura y tiempo de desarrollo.

5. Estado Actual del Proyecto
Hasta el momento, se ha avanzado en:

Definición de la arquitectura: Estructuración del backend y frontend.

Desarrollo inicial del backend: Creación del entorno con Node.js y PostgreSQL.

Diseño de la base de datos: Estructuración inicial para almacenar datos de contaminación y predicciones futuras.

Preparación del entorno de desarrollo: Configuración del repositorio local y control de versiones con GitHub.

6. Próximos Pasos
Conectar la aplicación con la API del Ayuntamiento para obtener datos de calidad del aire.

Desarrollar el modelo de predicción en Python o R para estimar la contaminación a un día vista.

Implementar visualizaciones de datos con gráficos sobre la evolución de PM10 y NO2.

Crear el sistema de autenticación para usuarios registrados e internos.

Implementar el sistema de notificaciones y alertas.

Realizar pruebas y optimizaciones antes del despliegue.

7. Avances Realizados en la Implementación de la Base de Datos
7.1 Estructura de la Base de Datos
- Creación de tres tablas principales:
  * estaciones: Almacena información sobre las estaciones de medición (ID, título, dirección, población, provincia, coordenadas)
  * parametros: Contiene información sobre los parámetros medidos (parámetro, descripción, tag, unidad)
  * mediciones: Registra todas las mediciones realizadas (estación, fecha, periodo, valores de contaminantes)

7.2 Implementación de Scripts de Inserción de Datos
- Desarrollo del script insert_data.js para la inserción inicial de datos:
  * Conexión a PostgreSQL con configuración mediante variables de entorno
  * Implementación de transacciones para garantizar la integridad de los datos
  * Funciones específicas para insertar estaciones, parámetros y mediciones
  * Manejo de errores y cierre adecuado de conexiones

7.3 Procesamiento de Datos Históricos
- Creación del script insert_historico.js para procesar datos históricos:
  * Implementación de inserción por lotes (500 registros) para optimizar el rendimiento
  * Manejo de memoria mejorado con pausa/reanuda del stream de datos
  * Procesamiento de más de 980,000 registros históricos
  * Implementación de restricciones únicas para evitar duplicados en parámetros

7.4 Verificación y Validación de Datos
- Desarrollo de script query_data.js para consultar los datos insertados
- Verificación de la integridad de los datos en las tres tablas
- Comprobación de las relaciones entre tablas
- Validación del formato y tipos de datos

7.5 Optimizaciones Implementadas
- Uso de transacciones para garantizar la integridad de los datos
- Implementación de inserción por lotes para mejorar el rendimiento
- Manejo de valores nulos y conversión de tipos de datos
- Implementación de restricciones únicas para evitar duplicados
- Mejora en el manejo de memoria durante el procesamiento de grandes volúmenes de datos

7.6 Próximos Pasos en la Base de Datos
- Implementación de índices para optimizar las consultas frecuentes
- Desarrollo de vistas para facilitar el acceso a datos comunes
- Implementación de triggers para mantener la integridad referencial
- Preparación para la integración con la API del Ayuntamiento
- Desarrollo de scripts para la actualización periódica de datos


Ideas para enriquecer la app:

- Notificaciones a suscriptores por correo electrónico con la predicción del día.
- Generación de informes en pdf a petición (Ejemplo aplicación: jasper report). Hacerlo, que a Eduardo le gusta mucho.
- Fijarse en la usabilidad de la aplicación. Ejemplo: Implementar un sistema de recuperación de la contraseña.


8. Avances Realizados (8 de abril de 2024)
8.1 Implementación del Cliente API
- Desarrollo del módulo api_client.js para interactuar con la API del Ayuntamiento:
  * Configuración de conexión a la API de datos abiertos de Gijón
  * Implementación de paginación para obtener todos los registros disponibles
  * Manejo de errores y reintentos en las peticiones
  * Transformación y validación de datos antes de la inserción

8.2 Sistema de Actualización de Datos
- Creación de la tabla mediciones_api para datos en tiempo real:
  * Estructura optimizada para almacenar mediciones actuales
  * Implementación de restricciones para evitar duplicados
  * Campo de validación para verificar la calidad de los datos
  * Timestamps para seguimiento de actualizaciones

8.3 Scripts de Procesamiento
- Desarrollo de utilidades para el manejo de datos:
  * extraer_muestra.py: Script para generar conjuntos de datos de prueba
  * join_csvs.py: Herramienta para combinar múltiples fuentes de datos
  * Implementación de limpieza y validación de datos

8.4 Problemas Identificados y Soluciones Propuestas
- Detección de inconsistencias en las fechas de los datos:
  * Identificación de registros con fechas futuras (marzo 2025)
  * Presencia de datos históricos antiguos (octubre 2021)
  * Planificada la implementación de validación de fechas
  * Necesidad de filtrar datos inconsistentes

8.5 Control de Versiones
- Actualización del repositorio Git:
  * Configuración mejorada de .gitignore
  * Documentación de cambios y nuevas funcionalidades
  * Organización de código en módulos independientes
  * Preparación para integración continua

8.6 Próximos Pasos
- Implementar validación de fechas en el cliente API
- Desarrollar sistema de limpieza automática de datos inconsistentes
- Crear endpoints REST para acceder a los datos históricos
- Implementar sistema de caché para optimizar consultas frecuentes
- Desarrollar interfaz de administración para gestión de datos

8.7 Implementación del Cliente AQICN API (8 de abril de 2024)
- Análisis del script api_aqicn.js:
  * Integración con la API WAQI (World Air Quality Index)
  * Configuración de token de acceso mediante variables de entorno
  * Consulta específica a la estación ID 6699 (Avenida Constitución)
  * Obtención de datos en tiempo real:
    - Índice de calidad del aire (AQI)
    - Timestamp de la medición
    - Valores individuales de contaminantes

Observaciones y Recomendaciones:
1. Seguridad:
   * El token de API está hardcodeado como fallback
   * Recomendación: Mover el token a variables de entorno exclusivamente

2. Mejoras Propuestas:
   * Implementar manejo de errores más robusto
   * Añadir reintentos en caso de fallos de red
   * Crear función reutilizable para consultar diferentes estaciones
   * Integrar con el sistema de logging existente
   * Documentar los tipos de contaminantes disponibles

3. Integración:
   * Conectar con la tabla mediciones_api
   * Implementar sistema de cache para evitar llamadas excesivas
   * Añadir validación de datos antes de almacenamiento
   * Crear endpoints REST para exponer estos datos


9. Avances Realizados (25 de abril de 2024)
9.1 Implementación de Integración con AQICN API
- Desarrollo de un cliente para la API WAQI (World Air Quality Index):
  * Configuración de conexión segura mediante variables de entorno
  * Implementación de sistema de reintentos para peticiones fallidas
  * Parseo y normalización de datos de calidad del aire
  * Obtención de 10 parámetros críticos (PM2.5, PM10, NO2, SO2, O3, etc.)

9.2 Reestructuración de la Base de Datos
- Creación y optimización de la tabla mediciones_api:
  * Estructura optimizada para datos de múltiples parámetros
  * Restricciones de unicidad para evitar duplicados
  * Índices para mejorar el rendimiento de consultas
  * Triggers para gestionar automáticamente los timestamps
  * Soporte para el índice AQI y valores individuales por contaminante

9.3 Mejoras en el Sistema de Integración
- Implementación de transacciones para garantizar la integridad de los datos
- Manejo mejorado de errores y situaciones excepcionales
- Limpieza previa de la tabla para evitar problemas de formato
- Logging detallado del proceso de obtención e inserción de datos
- Configuración centralizada para facilitar el mantenimiento

9.4 Procesamiento de Datos en Tiempo Real
- Mapeo de valores de la API a la estructura de la base de datos
- Conversión y validación de tipos de datos
- Marcado de registros con origen verificado
- Almacenamiento del AQI general para cada medición

10. Próximos Pasos
10.1 Automatización
- Implementar un sistema de programación de tareas (cron) para actualizar datos periódicamente
- Crear mecanismos de rotación de datos históricos
- Desarrollar notificaciones automáticas ante cambios significativos en la calidad del aire

10.2 Visualización de Datos
- Crear endpoints API REST para acceder a los datos de calidad del aire
- Desarrollar componentes de frontend para mostrar el AQI actual
- Implementar gráficos de tendencias por hora/día/semana
- Diseñar dashboard con indicadores clave y alertas visuales

10.3 Mejoras y Validación
- Incorporar validación de fechas para detectar anomalías en los datos
- Implementar comparativas entre distintas fuentes de datos (AQICN vs. Ayuntamiento)
- Desarrollar análisis estadístico básico (medias, máximos, mínimos)
- Crear sistema de alertas basado en umbrales para los contaminantes críticos

10.4 Integración con el Modelo Predictivo
- Preparar los datos para alimentar al modelo de predicción
- Crear sistema de exportación de datos históricos en formato adecuado
- Desarrollar mecanismos para comparar predicciones vs. datos reales
- Implementar visualizaciones comparativas


11. Avances Realizados (20 de mayo de 2025)
11.1 Estructura mínima de frontend React
- Creación de la carpeta /frontend con Vite y React
- Implementación de un componente principal (App.jsx) y una tarjeta de calidad del aire (AirQualityCard.jsx)
- Configuración de Vite para desarrollo local con proxy al backend
- Instalación y configuración de dependencias necesarias (react, react-dom, vite, @vitejs/plugin-react)

11.2 Integración frontend-backend
- Consumo del endpoint /api/air/constitucion/pm10 desde el frontend
- Visualización en tiempo real del valor de PM10 y su estado
- Pruebas locales exitosas con datos reales de la base de datos

11.3 Solución de problemas y pruebas
- Resolución de errores de dependencias y scripts de npm
- Verificación de la actualización de datos mediante ejecución manual de node api_aqicn.js
- Comprobación de la correcta visualización de la fecha y el valor de PM10

11.4 Documentación y control de versiones
- Actualización del README.md para reflejar la estructura real del proyecto y los pasos de uso
- Actualización de la memoria del proyecto con la documentación técnica de la API
- Commit y push de todos los cambios a GitHub

Próximos pasos:
- Ordenar la estructura del monorepo para despliegue en Render
- Automatizar la actualización de datos (cron)
- Mejorar el frontend y añadir nuevas visualizaciones
- Preparar la documentación final para entrega


12. Avances Realizados (23 de mayo de 2025)
12.1 Despliegue backend en Render
- Configuración y despliegue exitoso del backend Node.js en Render
- Configuración de variables de entorno para producción

12.2 Creación y conexión de base de datos PostgreSQL en Render
- Creación de instancia PostgreSQL en Render
- Obtención y uso de la INTERNAL DATABASE URL para el backend
- Configuración de la conexión en variables de entorno

12.3 Creación de tablas en la nueva base de datos
- Conexión a la base de datos de Render mediante pgAdmin
- Ejecución de scripts SQL para crear las tablas necesarias (`estaciones`, `mediciones_api`, triggers, etc.)
- Verificación de la estructura y correcto funcionamiento

12.4 Verificación y logs
- Revisión de logs en Render para asegurar la conexión y la creación de tablas
- Confirmación de que el backend está live y sin errores críticos

Próximos pasos:
- Poblar la base de datos de Render con datos reales de AQICN
- Probar el endpoint en producción
- Desplegar el frontend y conectar con el backend en Render


13. Avances Realizados (26 de mayo de 2025)
13.1 Diagnóstico y Solución de Problemas del Cron Job
- Identificación del problema: Cron job configurado en Render fallando con "Exited with status 1"
- Análisis de la causa: Falta de variables de entorno (DATABASE_URL) en el contexto del cron job
- Creación de script de diagnóstico (debug_cron.js) para identificar problemas específicos
- Desarrollo de script robusto alternativo (cron_update.js) con mejor manejo de errores

13.2 Mejoras en el Sistema de Datos Históricos
- Confirmación del funcionamiento del sistema de acumulación de datos históricos
- Verificación de que los datos se mantienen sin eliminarse (solo limpieza >30 días)
- Comprobación de la detección de duplicados y actualización inteligente
- Validación del crecimiento de registros: de 10 a 20 registros tras nueva ejecución

13.3 Análisis de la Base de Datos en Producción
- Investigación sobre por qué solo aparecen 10 registros en pgAdmin
- Confirmación de que es normal: 10 parámetros por cada consulta a AQICN API
- Explicación de la estructura: cada hora genera 10 registros (h, no2, o3, p, pm10, pm25, so2, t, w, wg)
- Verificación de que el sistema funciona correctamente, solo necesita más ejecuciones

13.4 Mejoras en el Frontend
- Modernización del diseño con paleta de colores más suave (azules #3B82F6, #60A5FA)
- Implementación de gradientes elegantes en logo, botones y fondos
- Mejora de la tipografía con efecto degradado en "AirWise Gijón"
- Header modernizado con fondo translúcido y efecto backdrop-filter
- Navegación en píldoras con diseño más elegante
- Tarjeta de calidad del aire rediseñada con sombras dramáticas y efecto hover
- Navegación móvil elegante con efecto glassmorphism
- Componentes de estado mejorados (LoadingCard con shimmer, error cards elegantes)
- Optimización responsive con mobile-first approach

13.5 Corrección del Layout Móvil
- Solución del problema de orden en móvil: tarjeta principal ahora aparece primero
- Implementación de order CSS para priorizar información principal sin scroll
- Mejora de la experiencia de usuario en dispositivos móviles

13.6 Scripts de Gestión y Diagnóstico Creados
- debug_cron.js: Diagnóstico completo del entorno del cron job
- cron_update.js: Versión robusta del script de actualización
- Actualización de package.json con nuevos scripts:
  * npm run debug-cron: Para diagnosticar problemas
  * npm run cron-update: Script alternativo más robusto

13.7 Documentación y Preparación para Predicciones
- Clarificación de la diferencia entre dos cron jobs:
  * Cron Job 1: Importación de datos AQICN (fallando, necesita arreglo)
  * Cron Job 2: Sistema de predicciones (para configurar mañana)
- Preparación de la infraestructura para el sistema de predicciones diarias
- Sistema de promedios diarios y algoritmo ponderado semanal ya implementado

13.8 Problemas Identificados y Pendientes
- Cron job de importación AQICN fallando por falta de variables de entorno
- Necesidad de configurar DATABASE_URL en las variables de entorno del cron job en Render
- Errores locales de conexión en desarrollo (ECONNREFUSED) - normales en desarrollo
- Error "tuple concurrently updated" en base de datos local - problema de concurrencia

13.9 Despliegue y Control de Versiones
- Commit exitoso: "feat: Mejorar diseño del frontend con estilo moderno"
- 8 archivos modificados, 750 inserciones, 301 eliminaciones
- 1 archivo nuevo: LoadingCard.jsx
- Push exitoso a GitHub para despliegue automático en Render

Próximos pasos para mañana:
- Configurar variables de entorno DATABASE_URL en el cron job de Render
- Usar script de diagnóstico temporalmente para identificar problemas específicos
- Una vez solucionado, configurar el segundo cron job para predicciones diarias
- Monitorear el funcionamiento de ambos cron jobs
- Continuar con el desarrollo del sistema de predicciones y visualizaciones

# Puntos realizados - Sesión 27/28 mayo 2025

## Cambios y pruebas principales

- Revisión de la migración a PM2.5 y visualización de datos en frontend y backend.
- Petición de mejoras visuales: quitar botón "Mapa", cambiar nombre a "Air Gijón", mostrar solo PM2.5, actualizar límites OMS, etc.
- Actualización de la tarjeta de evolución:
  - Mostrar solo fechas (sin "Hoy"/"Mañana") para evitar confusión.
  - Mejor distinción visual entre datos históricos y predicciones.
  - Se probaron barras de confianza para predicciones, pero se descartaron por claridad visual.
- Se detectó que la predicción del día siguiente no aparecía correctamente:
  - Se revisó la lógica de generación de predicciones y la función obtenerEvolucion.
  - Se comprobó que el sistema solo generaba predicción para "hoy" y "mañana" según la fecha del servidor.
  - Se identificó que el 26 de mayo seguía como "predicción" en vez de "histórico".
  - Se intentó corregir manualmente el tipo en la base de datos.
- Se propuso una lógica robusta para predicciones (validación de datos horarios del día anterior), pero se decidió posponer su implementación para no romper la funcionalidad.
- Se revirtió la función de predicción a la versión simple (predicción para hoy y mañana, sin validaciones extra).
- Se comprobó que los endpoints backend devolvían datos correctamente (tanto en local como en producción Render).
- Se hizo commit y push de los cambios para que Render redesplegara la app y se volviesen a ver datos en la web.

## Estado final

- La app vuelve a mostrar datos correctamente en frontend y backend.
- El gráfico de evolución muestra solo fechas, sin barras de confianza.
- La distinción entre históricos y predicciones es clara.
- El sistema de predicciones está en modo simple (sin validaciones de datos horarios).
- Pendiente: implementar lógica de validación de datos horarios para predicciones y alerta visual cuando falten datos.


